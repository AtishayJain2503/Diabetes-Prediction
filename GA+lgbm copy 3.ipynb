{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import special\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report, accuracy_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn_genetic import GAFeatureSelectionCV\n",
    "from sklearn_genetic.callbacks import ProgressBar, ConsecutiveStopping, TensorBoard\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', '{:20,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('/Users/sakshamjain/Desktop/Projects/JAIN-WIN/X_train_corr.csv')\n",
    "y_train = pd.read_csv('/Users/sakshamjain/Desktop/Projects/JAIN-WIN/y_train_large.csv').squeeze()\n",
    "X_test = pd.read_csv('/Users/sakshamjain/Desktop/Projects/JAIN-WIN/X_test_corr.csv')\n",
    "y_test = pd.read_csv('/Users/sakshamjain/Desktop/Projects/JAIN-WIN/y_test_large.csv').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = X_train.columns.str.replace(' ', '_')\n",
    "X_test.columns = X_test.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training LightGBM model...\")\n",
    "model = lgb.LGBMClassifier( random_state=69, n_jobs=-1, force_col_wise=True ,verbose=0)\n",
    "# Train the initial LightGBM model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate classification metrics\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC-ROC:\", auc_roc)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame for importance\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = importance_df.sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Calculate cumulative importance\n",
    "importance_df['cumulative_importance'] = importance_df['importance'].cumsum() / importance_df['importance'].sum()\n",
    "\n",
    "# Select features contributing to 95% of cumulative importance\n",
    "selected_features = importance_df[importance_df['cumulative_importance'] <= 0.95]['feature']\n",
    "\n",
    "# Filter the train and test sets for selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Retrain the model using the selected features\n",
    "model_selected = lgb.LGBMClassifier(random_state=69, n_jobs=-1, force_col_wise=True)\n",
    "\n",
    "# Train the model again on the selected features\n",
    "model_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred_selected = model_selected.predict_proba(X_test_selected)[:, 1]\n",
    "auc_roc_selected = roc_auc_score(y_test, y_pred_selected)\n",
    "\n",
    "print(f\"AUC-ROC on the selected features: {auc_roc_selected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_selected.copy()\n",
    "X_test=X_test_selected.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dataframes():\n",
    "    # This will check for variables that are instances of pd.DataFrame in the global scope\n",
    "    return {name: obj for name, obj in globals().items() if isinstance(obj, pd.DataFrame)}\n",
    "\n",
    "def print_memory_usage_of_dataframes():\n",
    "    dataframes = find_dataframes()\n",
    "    total_memory = 0\n",
    "    print(\"Memory usage of dataframes (in GB):\")\n",
    "    for name, df in dataframes.items():\n",
    "        mem_usage = df.memory_usage(deep=True).sum() / 1024 ** 3  # Convert bytes to gigabytes\n",
    "        total_memory += mem_usage\n",
    "        print(f\"{name}: {mem_usage:.6f} GB\")\n",
    "    print(f\"Total memory used by dataframes: {total_memory:.6f} GB\")\n",
    "\n",
    "print_memory_usage_of_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del _,_4,importance_df,X_train_selected,X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier( random_state=69, n_jobs=-1, force_col_wise=True ,verbose=1)\n",
    "\n",
    "\n",
    "rfe = RFE(estimator=model, n_features_to_select=639, step=0.05)\n",
    "print(\"Fitting RFE...\")\n",
    "rfe.fit(X_train, y_train)\n",
    "print(\"RFE fitting completed.\\n\")\n",
    "\n",
    "# Get the selected features\n",
    "selected_features_rfe = X_train.columns[rfe.support_].tolist()\n",
    "print(f\"Selected {len(selected_features_rfe)} features after RFE: {selected_features_rfe}\\n\")\n",
    "\n",
    "X_train_rfe = X_train[selected_features_rfe]\n",
    "X_test_rfe = X_test[selected_features_rfe]\n",
    "\n",
    "# Train LightGBM on RFE-selected Features\n",
    "print(\"Training LightGBM model on RFE-selected features...\")\n",
    "model_rfe = lgb.LGBMClassifier( random_state=69, n_jobs=-1, force_col_wise=True )\n",
    "model_rfe.fit(X_train_rfe, y_train)\n",
    "print(\"Model trained on RFE-selected features.\\n\")\n",
    "\n",
    "# Predictions and Probabilities\n",
    "y_pred_rfe = model_rfe.predict(X_test_rfe)\n",
    "y_proba_rfe = model_rfe.predict_proba(X_test_rfe)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "print(\"Classification Report for RFE-selected Features:\")\n",
    "print(classification_report(y_test, y_pred_rfe))\n",
    "auc_rfe = roc_auc_score(y_test, y_proba_rfe)\n",
    "print(f\"AUC-ROC for RFE-selected Features: {auc_rfe:.8f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_rfe.copy()\n",
    "X_test=X_test_rfe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_rfe,X_test_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier( random_state=69, n_jobs=-1, force_col_wise=True,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector=GAFeatureSelectionCV(\n",
    "    estimator=model,\n",
    "    max_features=320,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    "    generations=3,\n",
    "    population_size=200\n",
    ")\n",
    "\n",
    "\n",
    "progress_bar = ProgressBar()\n",
    "tensor= TensorBoard()\n",
    "stopper= ConsecutiveStopping(generations=5, metric=\"fitness_max\")\n",
    "callbacks = [progress_bar, tensor, stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.fit(X_train, y_train,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_mask = selector.support_\n",
    "\n",
    "selected_features = X_train.columns[selected_features_mask]\n",
    "num_features_selected = len(selected_features)\n",
    "print(f\"Number of features selected: {num_features_selected}\")\n",
    "print(\"Selected Features:\")\n",
    "print(\"selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_selected)\n",
    "y_pred_proba = model.predict_proba(X_test_selected)[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# AUC-ROC Score\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC-ROC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "#Assuming X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Define parameter sets\n",
    "lparams = {}\n",
    "\n",
    "lparams[0] = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 200,\n",
    "    'max_bin': 500,\n",
    "    'min_child_weight': 0.035,\n",
    "    'subsample': 0.45,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'min_data_in_leaf': 150,\n",
    "    'max_depth': -1,\n",
    "    'reg_alpha': 0.4,\n",
    "    'reg_lambda': 0.7,\n",
    "    'verbose': 1,\n",
    "    'random_state': 0,  # Combining seed and bagging_seed for reproducibility\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 30000\n",
    "}\n",
    "\n",
    "# Initialize models\n",
    "model_0 = lgb.LGBMClassifier(**lparams[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models with early stopping\n",
    "model_0.fit(\n",
    "    X_train_selected, y_train,\n",
    "    eval_set=[(X_test_selected, y_test)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=300),\n",
    "        log_evaluation(period=1)  \n",
    "    ]\n",
    ")\n",
    "\n",
    "preds_0 = model_0.predict_proba(X_test_selected)[:, 1]\n",
    "auc_0 = roc_auc_score(y_test, preds_0)\n",
    "print(f\"Model 0 AUC: {auc_0:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
